{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# mlrose Generator and Runner Usage Examples - Andrew Rollings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These examples will not solve assignment 2 for you, but they will give you\n",
    "some idea on how to use the problem generator and runner classes.\n",
    "\n",
    "Hopefully this will result in slightly fewer\n",
    "\"How do I &lt;insert basic usage here&gt;?\" questions every semester...\n",
    "\n",
    "Also, and in case it hasn't been made clear enough by the TAs, using any of the visualization code in here for your\n",
    "assignment is a bad idea, for two reasons... (1) It provides nothing useful as far as the assignment goes,\n",
    "and (2) the TAs will undoubtedly frown upon it.\n",
    "\n",
    "Visualization is part of the analysis and, for the most part, you're supposed to do that by yourself. Just including\n",
    "images of the before/after state of a problem really isn't useful in terms of what you're supposed to be analyzing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q2/n6gs30t12tddx_g65ffkf_h4w_msz4/T/ipykernel_60419/596531505.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML # for some notebook formatting.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chess'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstring\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mast\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m literal_eval\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mchess\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_iris\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'chess'"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML # for some notebook formatting.\n",
    "\n",
    "import mlrose\n",
    "import numpy as np\n",
    "import logging\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "\n",
    "from ast import literal_eval\n",
    "import chess\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlrose import QueensGenerator, MaxKColorGenerator, TSPGenerator\n",
    "from mlrose import SARunner, GARunner, NNGSRunner\n",
    "\n",
    "# switch off the chatter\n",
    "logging.basicConfig(level=logging.WARNING)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example 1: Generating and Running 8-Queens using the SA algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate a new 8-Queen problem using a fixed seed.\n",
    "problem = QueensGenerator().generate(seed=123456, size=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The initial state is as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state = problem.get_state()\n",
    "print(state)\n",
    "board_layout = '/'.join([''.join(([str(s)] if s > 0 else []) + ['Q'] + ([str((7-s))] if s < 7 else [])) for s in state])\n",
    "board = chess.Board(board_layout)\n",
    "board"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a runner class and solve the problem\n",
    "sa = SARunner(problem=problem,\n",
    "              experiment_name='queens8_sa',\n",
    "              output_directory=None, # note: specify an output directory to have results saved to disk\n",
    "              seed=123456,\n",
    "              iteration_list=2 ** np.arange(11),\n",
    "              max_attempts=500,\n",
    "              temperature_list=[0.1, 0.5, 0.75, 1.0, 2.0, 5.0],\n",
    "              decay_list=[mlrose.GeomDecay])\n",
    "\n",
    "# the two data frames will contain the results\n",
    "df_run_stats, df_run_curves = sa.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The preceding code will run the `SA` algorithm six times for at most 1024 iterations.\n",
    "Each run is initialized with the temperature specified in the `temperature_list`\n",
    "using the temperature values specified.\n",
    "\n",
    "If the fitness remains static for `max_attempts` iterations, it will terminate that run.\n",
    "\n",
    "Note that the initial state parameters here are just toy values picked specifically\n",
    "for this example. You will have to choose your own range of values for your\n",
    "assignment. I strongly recommend you don't just copy these, or you will find\n",
    "that the grading is unlikely to go the way you would like.\n",
    "\n",
    "The output in the `df_run_stats` dataframe contains snapshots of the state of the algorithm at the iterations\n",
    "specified in the `iteration_list` passed into the runner class.\n",
    "\n",
    "The first 12 rows (corresponding to the first run of this algorithm) are as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(df_run_stats[['Iteration', 'Fitness', 'FEvals', 'Time', 'State']][0:12].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The state information is excluded from the previous output.\n",
    "\n",
    "A sample of this (based on the state of the `GeomDecay` object) is below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state_sample = df_run_stats[['schedule_current_value', 'schedule_init_temp', 'schedule_min_temp']][:1]\n",
    "HTML(state_sample.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, to pick out the most performant run from the dataframe, you need to find the row with the best fitness.\n",
    "As 8-Queens is a minimization problem, you'd pick the row with the minimum fitness.\n",
    "\n",
    "However, I'm going to look in the `run_curves` (which stores minimal basic information every iteration) to\n",
    "find out which input state achieved the best fitness in the fewest fitness evaluations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_fitness = df_run_curves['Fitness'].min()\n",
    "best_runs = df_run_curves[df_run_curves['Fitness'] == best_fitness]\n",
    "\n",
    "HTML(best_runs.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us five candidates for the best run. We are going to pick the one with\n",
    "that reached the best fitness value in the fewest number of evaluations.\n",
    "\n",
    "(We could also have chosen to use `Iterations` as our criteria.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "minimum_evaluations = best_runs['FEvals'].min()\n",
    "\n",
    "best_curve_run = best_runs[best_runs['FEvals'] == minimum_evaluations]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best run using these criteria is as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(best_curve_run.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which has the following identifying state information:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_init_temperature = best_curve_run['Temperature'].iloc()[0].init_temp\n",
    "\n",
    "print(f'Best initial temperature: {best_init_temperature}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To map this back to the `run_stats` we look at the configuration data included in\n",
    "the curve data. The curve data includes at least the minimum identifying information\n",
    "to determine which run each row came from.\n",
    "\n",
    "In this case, the value we are looking for is the `Temperature`, which is the initial temperature\n",
    "used to initialize the `GeomDecay` object.\n",
    "\n",
    "So, in this case, we are looking for all rows in `df_run_stats` where the temperature is equal to 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_stats_best_run = df_run_stats[df_run_stats['schedule_init_temp'] == best_init_temperature]\n",
    "HTML(run_stats_best_run[['Iteration', 'Fitness', 'FEvals', 'Time', 'State']].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And the best state associated with this is:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_state = run_stats_best_run[['schedule_current_value', 'schedule_init_temp', 'schedule_min_temp']].tail(1)\n",
    "HTML(best_state.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final state is as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state = literal_eval(run_stats_best_run['State'].tail(1).values[0])\n",
    "print(state)\n",
    "board_layout = '/'.join([''.join(([str(s)] if s > 0 else []) + ['Q'] + ([str((7-s))] if s < 7 else [])) for s in state])\n",
    "board = chess.Board(board_layout)\n",
    "board"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example 2: Generating and Running Max K Color using the GA algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate a new Max K problem using a fixed seed.\n",
    "problem = MaxKColorGenerator().generate(seed=123456, number_of_nodes=10, max_connections_per_node=3, max_colors=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The input graph generated for the problem looks like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nx.draw(problem.source_graph,\n",
    "        pos=nx.spring_layout(problem.source_graph, seed = 3))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a runner class and solve the problem\n",
    "ga = GARunner(problem=problem,\n",
    "              experiment_name='max_k_ga',\n",
    "              output_directory=None, # note: specify an output directory to have results saved to disk\n",
    "              seed=123456,\n",
    "              iteration_list=2 ** np.arange(11),\n",
    "              population_sizes=[10, 20, 50],\n",
    "              mutation_rates=[0.1, 0.2, 0.5])\n",
    "\n",
    "# the two data frames will contain the results\n",
    "df_run_stats, df_run_curves = ga.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The preceding code will run the `GA` algorithm nine times for at most 1024 iterations per run.\n",
    "Each run is a permutation from the list of `population_sizes` and `mutation_rates`.\n",
    "\n",
    "Note that the initial state parameters here are just toy values picked specifically\n",
    "for this example. You will have to choose your own range of values for your\n",
    "assignment. I strongly recommend you don't just copy these, or you will find\n",
    "that the grading is unlikely to go the way you would like.\n",
    "\n",
    "Really. I mean it... A mutation rate of 0.5 is little better than a pure random search.\n",
    "\n",
    "The output in the `df_run_stats` dataframe contains snapshots of the state of the algorithm at the iterations\n",
    "specified in the `iteration_list` passed into the runner class.\n",
    "\n",
    "The first row (corresponding to the first run of this algorithm) are as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(df_run_stats[['Iteration', 'Fitness', 'FEvals', 'Time', 'State']][0:1].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The state information is excluded from the previous output.\n",
    "\n",
    "A sample of this is below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state_sample = df_run_stats[['Population Size', 'Mutation Rate']][:1]\n",
    "HTML(state_sample.to_html())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, to pick out the most performant run from the dataframe, you need to find the row with the best fitness.\n",
    "As Max-K-Color is a minimization problem, you'd pick the row with the minimum fitness.\n",
    "\n",
    "However, I'm going to look in the `run_curves` (which stores minimal basic information every iteration) to\n",
    "find out which input state achieved the best fitness in the fewest fitness evaluations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_fitness = df_run_curves['Fitness'].min()\n",
    "best_runs = df_run_curves[df_run_curves['Fitness'] == best_fitness]\n",
    "\n",
    "HTML(best_runs.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us nine candidates for the best run. We are going to pick the one with\n",
    "that reached the best fitness value in the fewest number of evaluations.\n",
    "\n",
    "(We could also have chosen to use `Iterations` as our criteria.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "minimum_evaluations = best_runs['FEvals'].min()\n",
    "\n",
    "best_curve_run = best_runs[best_runs['FEvals'] == minimum_evaluations]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best runs using these criteria is as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(best_curve_run.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will arbitrarily pick the first row for this example,\n",
    "which has the following identifying state information:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_mr = best_curve_run['Mutation Rate'].iloc()[0]\n",
    "best_pop_size = best_curve_run['Population Size'].iloc()[0]\n",
    "print(f'Best Mutation Rate: {best_mr}, best Population Size: {best_pop_size}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To map this back to the `run_stats` we look at the configuration data included in\n",
    "the curve data. The curve data includes at least the minimum identifying information\n",
    "to determine which run each row came from.\n",
    "\n",
    "In this case, the values we are looking for are the `Mutation Rate` and `Population Size`.\n",
    "\n",
    "So, we are looking for all rows in `df_run_stats` where the mutation rate and population size are equal to our best values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_stats_best_run = df_run_stats[(df_run_stats['Mutation Rate'] == best_mr) & (df_run_stats['Population Size'] == best_pop_size)]\n",
    "HTML(run_stats_best_run[['Iteration', 'Fitness', 'FEvals', 'Time']].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And the best state associated with this is:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_state = run_stats_best_run[['State']].tail(1)\n",
    "HTML(best_state.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the following node ordering:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print([n for n in problem.source_graph.nodes])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reordering the state by ascending node number gives the following:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "color_indexes = literal_eval(run_stats_best_run['State'].tail(1).values[0])\n",
    "ordered_state = [color_indexes[n] for n in problem.source_graph.nodes]\n",
    "print(ordered_state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which results in a graph looking like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = ['lightcoral', 'lightgreen', 'yellow']\n",
    "node_color_map = [colors[s] for s in ordered_state]\n",
    "\n",
    "nx.draw(problem.source_graph,\n",
    "        pos=nx.spring_layout(problem.source_graph, seed = 3),\n",
    "        with_labels=True,\n",
    "        node_color=node_color_map)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example 3: Generating and Running TSP using the GA algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate a new TSP problem using a fixed seed.\n",
    "problem = TSPGenerator().generate(seed=123456, number_of_cities=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The input graph generated for the problem looks like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)         # Prepare 2 plots\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "for i, (x,y) in enumerate(problem.coords):\n",
    "    ax.scatter(x,y, s=200, c='cornflowerblue')             # plot A\n",
    "node_labels = {k:str(v) for k, v in enumerate(string.ascii_uppercase) if k < len(problem.source_graph.nodes)}\n",
    "for i in node_labels.keys():\n",
    "    x,y = problem.coords[i]\n",
    "    plt.text(x, y, node_labels[i], ha=\"center\", va=\"center\", c='white', fontweight='bold',\n",
    "             bbox = dict(boxstyle=f\"circle,pad=0.15\", fc='cornflowerblue'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a runner class and solve the problem\n",
    "ga = GARunner(problem=problem,\n",
    "              experiment_name='tsp_ga',\n",
    "              output_directory=None, # note: specify an output directory to have results saved to disk\n",
    "              seed=123456,\n",
    "              iteration_list=2 ** np.arange(11),\n",
    "              population_sizes=[10, 20],\n",
    "              mutation_rates=[0.1, 0.25, 0.5])\n",
    "\n",
    "# the two data frames will contain the results\n",
    "df_run_stats, df_run_curves = ga.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The preceding code will run the `GA` algorithm nine times for at most 1024 iterations per run.\n",
    "Each run is a permutation from the list of `population_sizes` and `mutation_rates`.\n",
    "\n",
    "Note that the initial state parameters here are just toy values picked specifically\n",
    "for this example. You will have to choose your own range of values for your\n",
    "assignment. I strongly recommend you don't just copy these, or you will find\n",
    "that the grading is unlikely to go the way you would like.\n",
    "\n",
    "Really. I mean it... A mutation rate of 0.5 is little better than a pure random search.\n",
    "\n",
    "The output in the `df_run_stats` dataframe contains snapshots of the state of the algorithm at the iterations\n",
    "specified in the `iteration_list` passed into the runner class.\n",
    "\n",
    "The first row (corresponding to the first run of this algorithm) are as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(df_run_stats[['Iteration', 'Fitness', 'FEvals', 'Time', 'State']][0:1].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The state information is excluded from the previous output.\n",
    "\n",
    "A sample of this is below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state_sample = df_run_stats[['Population Size', 'Mutation Rate']][:1]\n",
    "HTML(state_sample.to_html())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, to pick out the most performant run from the dataframe, you need to find the row with the best fitness.\n",
    "As TSP is a minimization problem, you'd pick the row with the minimum fitness.\n",
    "\n",
    "However, I'm going to look in the `run_curves` (which stores minimal basic information every iteration) to\n",
    "find out which input state achieved the best fitness in the fewest fitness evaluations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_fitness = df_run_curves['Fitness'].min()\n",
    "best_runs = df_run_curves[df_run_curves['Fitness'] == best_fitness]\n",
    "\n",
    "HTML(best_runs[0:10].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us nine candidates for the best run. We are going to pick the one with\n",
    "that reached the best fitness value in the fewest number of evaluations.\n",
    "\n",
    "(We could also have chosen to use `Iterations` as our criteria.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "minimum_evaluations = best_runs['FEvals'].min()\n",
    "\n",
    "best_curve_run = best_runs[best_runs['FEvals'] == minimum_evaluations]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best runs using these criteria is as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(best_curve_run.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This has the following identifying state information:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_mr = best_curve_run['Mutation Rate'].iloc()[0]\n",
    "best_pop_size = best_curve_run['Population Size'].iloc()[0]\n",
    "print(f'Best Mutation Rate: {best_mr}, best Population Size: {best_pop_size}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To map this back to the `run_stats` we look at the configuration data included in\n",
    "the curve data. The curve data includes at least the minimum identifying information\n",
    "to determine which run each row came from.\n",
    "\n",
    "In this case, the values we are looking for are the `Mutation Rate` and `Population Size`.\n",
    "\n",
    "So, we are looking for all rows in `df_run_stats` where the mutation rate and population size are equal to our best values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_stats_best_run = df_run_stats[(df_run_stats['Mutation Rate'] == best_mr) & (df_run_stats['Population Size'] == best_pop_size)]\n",
    "HTML(run_stats_best_run[['Iteration', 'Fitness', 'FEvals', 'Time']].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And the best state associated with this is:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_state = run_stats_best_run[['State']].tail(1)\n",
    "HTML(best_state.to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which results in a graph looking like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ordered_state = literal_eval(run_stats_best_run['State'].tail(1).values[0])\n",
    "edge_labels = {(ordered_state[i], ordered_state[(i+1) % len(ordered_state)]):f'{str(i+1)}âžœ' for i in range(len(ordered_state))}\n",
    "# print(ordered_state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)         # Prepare 2 plots\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "for i, (x,y) in enumerate(problem.coords):\n",
    "    ax.scatter(x,y, s=1,c='green' if i == 5 else 'cornflowerblue')             # plot A\n",
    "\n",
    "\n",
    "for i in range(len(ordered_state)):\n",
    "    start_node = ordered_state[i]\n",
    "    end_node = ordered_state[(i+1) % len(ordered_state)]\n",
    "    start_pos = problem.coords[start_node]\n",
    "    end_pos = problem.coords[end_node]\n",
    "    ax.annotate(\"\",\n",
    "            xy=start_pos, xycoords='data',\n",
    "            xytext=end_pos, textcoords='data',\n",
    "            c='red',\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            ec='red',\n",
    "                            connectionstyle=\"arc3\"))\n",
    "node_labels = {k:str(v) for k, v in enumerate(string.ascii_uppercase) if k < len(problem.source_graph.nodes)}\n",
    "\n",
    "for i in node_labels.keys():\n",
    "    x,y = problem.coords[i]\n",
    "    plt.text(x, y, node_labels[i], ha=\"center\", va=\"center\", c='white', fontweight='bold',\n",
    "             bbox = dict(boxstyle=f\"circle,pad=0.15\", fc='green' if i == ordered_state[0] else 'cornflowerblue'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And, to verify that the route is correct (or at least, the shortest one found):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_edge_lengths = {(x, y):d for x, y, d in problem.distances}\n",
    "all_edge_lengths.update({(y, x):d for x, y, d in problem.distances})\n",
    "\n",
    "route_length = sum([all_edge_lengths[k] for k in edge_labels.keys()])\n",
    "print(f'route_length: ({round(route_length, 6)}) equal to best_fitness: ({round(best_fitness, 6)})')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example 4: Using the NNGSRunner with the RHC algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load and Split data into training and test sets\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size = 0.3, random_state = 123456\n",
    ")\n",
    "\n",
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()\n",
    "\n",
    "grid_search_parameters = {\n",
    "    'max_iters': [1000],                          # nn params\n",
    "    'learning_rate': [1e-2],                       # nn params\n",
    "    'activation': [mlrose.relu],            # nn params\n",
    "    'restarts': [1],                             # rhc params\n",
    "}\n",
    "\n",
    "nnr = NNGSRunner(\n",
    "    x_train=X_train_scaled,\n",
    "    y_train=y_train_hot,\n",
    "    x_test=X_test_scaled,\n",
    "    y_test=y_test_hot,\n",
    "    experiment_name='nn_test_rhc',\n",
    "    algorithm=mlrose.algorithms.rhc.random_hill_climb,\n",
    "    grid_search_parameters=grid_search_parameters,\n",
    "    iteration_list=[1, 10, 50, 100, 250, 500, 1000],\n",
    "    hidden_layer_sizes=[[2]],\n",
    "    bias=True,\n",
    "    early_stopping=True,\n",
    "    clip_max=5,\n",
    "    max_attempts=500,\n",
    "    n_jobs=5,\n",
    "    seed=123456,\n",
    "    output_directory=None\n",
    ")\n",
    "\n",
    "\n",
    "run_stats_df, curves_df, cv_results_df, grid_search_cv = nnr.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The runner returns the `run_stats` and `curves` corresponding to *best* hyperparameter combination,\n",
    "as well as the cross validation results and the underlying `GridSearchCV` object used in the run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test_pred = grid_search_cv.predict(X_test_scaled)\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(y_test_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_pred = grid_search_cv.predict(X_train_scaled)\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "print(y_train_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(run_stats_df[['current_restart', 'Iteration', 'Fitness', 'FEvals', 'Time', 'learning_rate']][0:14].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(curves_df[['current_restart', 'Iteration', 'Fitness', 'FEvals', 'Time', 'learning_rate']][0:20].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HTML(cv_results_df[['mean_test_score', 'rank_test_score', 'mean_train_score', 'param_activation', 'param_hidden_layer_sizes', 'param_learning_rate',\n",
    "                    'param_max_iters', 'param_restarts']].to_html())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}